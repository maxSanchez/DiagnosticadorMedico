{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 3\n",
    "En este experimento decidí usar redes neuronales, con una biblioteca llamada gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import csv\n",
    "import unicodedata\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "\tglobal etq\n",
    "\t# ignorar=open(\"stopwords-es-master/stopwords-es.txt\",\"r\").read().splitlines()\n",
    "\tignorar=[]\n",
    "\twith open(fname,\"r\") as f:\n",
    "\t\tlineas=map(lambda x:[i for i in x.split(\"|\",1)],f.read().splitlines())\n",
    "\t\tind=0\n",
    "\t\tfor row in lineas:\n",
    "\t\t\tif len(row)>1 and len(row[1])!=0:\n",
    "\t\t\t\taux=unicodedata.normalize('NFKD',row[1]).lower()\n",
    "\t\t\t\tfor i in ignorar:\n",
    "\t\t\t\t\taux=aux.replace(\" \"+i+\" \",\" \")\n",
    "\t\t\t\tif len(aux.split())>30:\n",
    "\t\t\t\t\tif tokens_only:\n",
    "\t\t\t\t\t\tyield gensim.utils.simple_preprocess(aux)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tyield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(aux), [ind])\n",
    "\t\t\t\t\tetq[ind]=row[0]\n",
    "\t\t\t\t\t# input(ind)\n",
    "\t\t\t\t\tind+=1\n",
    "\n",
    "def splitInv(cad,caracteres,stopwords):\n",
    "\tarreglo=[]\n",
    "\taux=\"\"\n",
    "\tcad=cad.lower()+\".\"\n",
    "\tfor c in cad:\n",
    "\t\tif c not in caracteres :\n",
    "\t\t\tif aux!=\"\" and aux not in stopwords:\n",
    "\t\t\t\tarreglo.append(aux)\n",
    "\t\t\taux=\"\"\n",
    "\t\telse:\n",
    "\t\t\taux+=c\n",
    "\treturn arreglo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la siguiente parte de código se configura y entrena el modelo, en los siguientes ejemplos uso un corpus pequeño y uno mas grande, el grande es datosLimpios.csv el cual tiene 1.6 M de contenido y el pequeño es datos.csv el cual tiene solo 879 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tengo', 'dolor', 'de', 'espalda', 'baja', 'por', 'las', 'noches', 'mejora', 'con', 'el', 'ejercicio', 'y', 'antibioticos', 'tuve', 'una', 'uveitis', 'en', 'mi', 'ojo', 'izquierdo', 'ademas', 'de', 'dolor', 'en', 'el', 'cuello', 'y', 'articulaciones', 'de', 'las', 'manos', 'ademas', 'tengo', 'hla', 'b', 'positivo']\n",
      "Documento Similar anorexia_nerviosa.html  0.3453219532966614: \n",
      "Documento Similar enfermedad-de-whipple.html  0.344423770904541: \n",
      "Documento Similar espondilitis_anquilosante.html  0.33348092436790466: \n",
      "Documento Similar sindrome-de-marfan.html  0.3235524296760559: \n",
      "['nariz', 'tapada', 'estornudos', 'aveces', 'tengo', 'en', 'el', 'paladar', 'mucho', 'moco']\n",
      "Documento Similar paperas.html  0.4160977602005005: \n",
      "Documento Similar polipos_intestinales.html  0.40721043944358826: \n",
      "Documento Similar ronquido.html  0.40517380833625793: \n",
      "Documento Similar tos_ferina.html  0.3965616822242737: \n",
      "['difficultad', 'para', 'respirar', 'tos', 'fatiga', 'produccion', 'excesiva', 'de', 'moco']\n",
      "Documento Similar silicosis.html  0.4841383695602417: \n",
      "Documento Similar cancer_testiculo.html  0.482661634683609: \n",
      "Documento Similar adenoma-hipofisiario.html  0.4428844153881073: \n",
      "Documento Similar rectocele.html  0.43936580419540405: \n"
     ]
    }
   ],
   "source": [
    "etq={}\n",
    "# stopwords=open(\"stopwords-es-master/stopwords-es.txt\",\"r\").read().splitlines()\n",
    "stopwords=[]\n",
    "train_corpus = list(read_corpus(\"datosLimpios.csv\"))\n",
    "model = gensim.models.doc2vec.Doc2Vec(\n",
    "\tvector_size=100,\n",
    "\tmin_count=2,\n",
    "\twindow=5,\n",
    "\t# dm=1,\n",
    "\tdm_concat=1,\n",
    "\t# dbow_words=1,\n",
    "\tepochs=450,\n",
    "\tworkers=16,\n",
    "\t# ns_exponent=0\n",
    "\t)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "texto=splitInv(open(\"misSintomas.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))\n",
    "# -\n",
    "texto=splitInv(open(\"misSintomas2.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))\n",
    "\n",
    "# -\n",
    "texto=splitInv(open(\"misSintomas3.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver este modelo sirve mejor cuando se le dan entre 500 y 600 epoch,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tengo', 'dolor', 'de', 'espalda', 'baja', 'por', 'las', 'noches', 'mejora', 'con', 'el', 'ejercicio', 'y', 'antibioticos', 'tuve', 'una', 'uveitis', 'en', 'mi', 'ojo', 'izquierdo', 'ademas', 'de', 'dolor', 'en', 'el', 'cuello', 'y', 'articulaciones', 'de', 'las', 'manos', 'ademas', 'tengo', 'hla', 'b', 'positivo']\n",
      "Documento Similar espondilitis-anquilosante.html  0.44475024938583374: \n",
      "Documento Similar glaucoma.html  0.42014431953430176: \n",
      "Documento Similar incontinencia-urinaria.html  0.4023008346557617: \n",
      "Documento Similar ojo-seco.html  0.3839343190193176: \n",
      "['nariz', 'tapada', 'estornudos', 'aveces', 'tengo', 'en', 'el', 'paladar', 'mucho', 'moco']\n",
      "Documento Similar dismorfofobia.html  0.6507455706596375: \n",
      "Documento Similar gastritis.html  0.5277287364006042: \n",
      "Documento Similar bronquitis.html  0.5262576341629028: \n",
      "Documento Similar faringitis.html  0.5222646594047546: \n",
      "['difficultad', 'para', 'respirar', 'tos', 'fatiga', 'produccion', 'excesiva', 'de', 'moco']\n",
      "Documento Similar enfisema.html  0.6038917303085327: \n",
      "Documento Similar epoc.html  0.5264810919761658: \n",
      "Documento Similar hirsutismo.html  0.5033985376358032: \n",
      "Documento Similar fiebre-del-heno.html  0.4937693476676941: \n"
     ]
    }
   ],
   "source": [
    "train_corpus = list(read_corpus(\"../datos.csv\"))\n",
    "model = gensim.models.doc2vec.Doc2Vec(\n",
    "\tvector_size=100,\n",
    "\tmin_count=5,\n",
    "\twindow=2,\n",
    "\tdm=0,\n",
    "\tdm_concat=1,\n",
    "\t# dbow_words=0,\n",
    "\tepochs=300,\n",
    "\tworkers=16,\n",
    "\tns_exponent=1.125\n",
    "\t)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "texto=splitInv(open(\"misSintomas.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))\n",
    "# -\n",
    "texto=splitInv(open(\"misSintomas2.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))\n",
    "\n",
    "# -\n",
    "texto=splitInv(open(\"misSintomas3.txt\").read(),\"qwertyuiopasdfghjklzxcvbnm\",stopwords)\n",
    "print(texto)\n",
    "vector=model.infer_vector(texto)\n",
    "sim=model.docvecs.most_similar([vector],topn=4)\n",
    "for i in sim:\n",
    "\tprint(\"Documento Similar %s %s: \" % (etq[i[0]],i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este modelo ya entrenado, podemos predecir que enfermedad es "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Como conclusión de este experimento, pudimos ver que no funciona realmente como queremos, entre más grande sea nuestro corpus, se necesitan más epoch para entrenar, además de esto es necesario calcular un rango específico de las epoch ya que si son muchas, el sistema se sobre entrena, y dado que no son datos balanceados, es decir no hay el mismo número de enfermedades relacionadas con los huesos, la garganta, la cabeza etc., por lo tanto este sistema está más desviado a predecir ciertar enfermedades."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
